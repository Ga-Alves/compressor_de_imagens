{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "import heapq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization = np.array([\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99],\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DCT Function\n",
    "Description:\n",
    "    Calculate the transformed of a image, breaking it in bloks of 8x8\n",
    "    Use two times the dct for 1D, each time for one axis of the image\n",
    "Input: Original image\n",
    "Output: image transformed\n",
    "Warning: Need to deal with images that are not multiple of 8\n",
    "'''\n",
    "\n",
    "def DCT(img):\n",
    "    Y = np.zeros(img.shape)\n",
    "\n",
    "    U = img.shape[0]//8\n",
    "    V = img.shape[1]//8\n",
    "\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            img_blck = img[u*8: u*8 + 8, v*8: v*8 + 8]\n",
    "            Y[u*8: u*8 + 8, v*8: v*8 + 8] = dct(dct(img_blck, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT + Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: quant_DCT\n",
    "Description:\n",
    "    For each block 8x8 from the image transformed\n",
    "    Is divided by the quantization matrix\n",
    "\n",
    "Input: image transformed\n",
    "Output: image tranformed divided by quantization \n",
    "\n",
    "Warning: using the global variable img\n",
    "'''\n",
    "\n",
    "def quant_DCT(Y):\n",
    "    Y_quant = np.zeros(img.shape)\n",
    "    U = img.shape[0]//8\n",
    "    V = img.shape[1]//8\n",
    "\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            Y_quant[u*8 : u*8 + 8, v*8 : v*8 + 8] = (Y[u*8 : u*8 + 8, v*8 : v*8 + 8] / quantization).round()\n",
    "            Y_quant[u*8 : u*8 + 8, v*8 : v*8 + 8] *= np.abs(Y_quant[u*8 : u*8 + 8, v*8 : v*8 + 8]) != 0\n",
    "    \n",
    "    return Y_quant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequant_DCT(Y_quant):\n",
    "    U = Y_quant.shape[0]//8\n",
    "    V = Y_quant.shape[1]//8\n",
    "    Y_dequant = np.zeros(Y_quant.shape)\n",
    "    \n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            Y_dequant[u*8 : u*8 + 8, v*8 : v*8 + 8] = Y_quant[u*8 : u*8 + 8, v*8 : v*8 + 8] * quantization\n",
    "    \n",
    "    return Y_dequant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iDCT(Y):\n",
    "\n",
    "    U = Y.shape[0]//8\n",
    "    V = Y.shape[1]//8\n",
    "    img_rec = np.zeros(Y.shape)\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            img_rec[u*8 : u*8 + 8, v*8 : v*8 + 8] = idct(idct(Y[u*8 : u*8 + 8, v*8 : v*8 + 8], axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "    \n",
    "    return img_rec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution and Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('imgs/naruto.webp', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = DCT(img)\n",
    "plt.hist(Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_quant = quant_DCT(Y)\n",
    "plt.hist(Y_quant)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Predição + matriz de erros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Func: weight_grey_tons\n",
    "Description:\n",
    "    Get the number of occurrence of each color\n",
    "Input: quantizated transformed image (Future: Error quantizated transformed image)\n",
    "Output: table with the occurrence of each color\n",
    "    [0     4] -> color 0 -> 4 times\n",
    "    [1     1] -> color 1 -> 1 time\n",
    "    [2     5]\n",
    "    [3     6]\n",
    "'''\n",
    "\n",
    "def weight_grey_tons(img):\n",
    "    # depth = 8\n",
    "    # nLine, nCols = img.shape\n",
    "    # hist = np.zeros((2**8))\n",
    "    \n",
    "    #get unique values and counts of each value\n",
    "    unique, counts = np.unique(img.flatten(), return_counts=True)\n",
    "\n",
    "    #display unique values and counts side by side\n",
    "    occurrence = np.asarray((unique, counts)).T\n",
    "\n",
    "    return occurrence\n",
    "\n",
    "'''\n",
    "Func: huffman_tree\n",
    "Description:\n",
    "    Create the the tree representation for the Huff Algorithm\n",
    "Input: Color occurency \n",
    "    Accept Format\n",
    "    [0     4] -> color 0 -> 4 times\n",
    "    [1     1] -> color 1 -> 1 time\n",
    "    [2     5]\n",
    "    [3     6]\n",
    "\n",
    "Output: Tree\n",
    "\n",
    "To-do\n",
    "    Priority_queue\n",
    "    Tree\n",
    "'''\n",
    "\n",
    "def huffman_tree(ocurrence):\n",
    "\n",
    "    nLine, _ = ocurrence.shape\n",
    "    \n",
    "    class Tree:\n",
    "        def __init__(self, data):\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.data = data\n",
    "\n",
    "    forest = []\n",
    "\n",
    "    # Populate the list\n",
    "    for i in range (nLine):\n",
    "        color, times =  ocurrence[i]\n",
    "        tree = Tree(color)\n",
    "        forest.append((times, color, tree)) # Why a tuple? Is easier to use a tuple than define a __lt__ to compare the objects\n",
    "\n",
    "    # Create a priority list\n",
    "    heapq.heapify(forest)\n",
    "\n",
    "\n",
    "    count = 300\n",
    "    while(len(forest) > 0):\n",
    "        first_small = heapq.heappop(forest)\n",
    "        second_small = heapq.heappop(forest)\n",
    "\n",
    "        tree\n",
    "\n",
    "    return first_small, second_small\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = weight_grey_tons(img)\n",
    "huffman_tree(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconpress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dequantizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dequant = dequant_DCT(Y_quant)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformada inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rec = iDCT(Y_dequant)\n",
    "plt.imshow((img_rec), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((img), cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {((img - img_rec)**2).sum()/img.size}')\n",
    "print(f'ME: {np.abs(img - img_rec).max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramas de Y e Y_quant para, posteriormente, criar matriz de erros para huffman\n",
    "# observe o eixo-x, i.e. os erros serão mais próximos\n",
    "plt.hist(Y)\n",
    "plt.show()\n",
    "plt.hist(Y_quant)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.unique(Y).size, np.unique(Y_quant).size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
