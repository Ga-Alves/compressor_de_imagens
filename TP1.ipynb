{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "import heapq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantization Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization = np.array([\n",
    "    [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "    [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "    [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "    [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "    [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "    [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "    [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "    [72, 92, 95, 98, 112, 100, 103, 99],\n",
    "])\n",
    "\n",
    "quantization_B = np.array([\n",
    "    [8, 6, 5, 8, 12, 20, 26, 31],\n",
    "    [6, 6, 7, 10, 13, 29, 30, 28],\n",
    "    [7, 7, 8, 12, 20, 29, 35, 28],\n",
    "    [7, 9, 11, 15, 26, 44, 40, 31],\n",
    "    [9, 11, 19, 28, 34, 55, 52, 39],\n",
    "    [12, 18, 28, 32, 41, 52, 57, 46],\n",
    "    [25, 32, 39, 44, 52, 61, 60, 51],\n",
    "    [36, 46, 48, 49, 56, 50, 52, 50],\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "predict function 1\n",
    "Description:\n",
    "    Calculate the f(x, y) = f(-x, y) prediction\n",
    "Input: x and y coordinates and the matrix of the coordinates\n",
    "Output: one prediction\n",
    "'''\n",
    "def predict_function_1(x, y, matrix):\n",
    "    M, N = matrix.shape\n",
    "\n",
    "    error = x >= M or y >= N\n",
    "    if error:\n",
    "        return\n",
    "    \n",
    "    if (x == 0 and y == 0):\n",
    "        return matrix[0][0]\n",
    "    if x > 0:\n",
    "        return matrix[x-1][y]\n",
    "    elif x == 0:\n",
    "        return matrix[x][y-1]\n",
    "\n",
    "'''\n",
    "predict function 2\n",
    "Description:\n",
    "    Calculate the f(x, y) = 0.5*f(-x, y) + 0.5*f(x, -y) prediction\n",
    "Input: x and y coordinates and the matrix of the coordinates\n",
    "Output: one prediction\n",
    "'''\n",
    "def predict_function_2(x, y, matrix):\n",
    "    M, N = matrix.shape\n",
    "\n",
    "    error =  x >= M or y >= N\n",
    "    if error:\n",
    "        return\n",
    "    \n",
    "    if (x == 0 and y == 0):\n",
    "        return matrix[0][0]\n",
    "    \n",
    "    if y == 0:\n",
    "        return matrix[x-1][y]\n",
    "    elif x == 0:\n",
    "        return matrix[x][y-1]\n",
    "    elif x > 0 and y > 0:\n",
    "        return .5 * matrix[x-1][y] + .5 * matrix[x][y-1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DCT Function\n",
    "Description:\n",
    "    Calculate the transformed of a image, breaking it in bloks of 8x8\n",
    "    Use two times the dct for 1D, each time for one axis of the image\n",
    "Input: Original image\n",
    "Output: image transformed\n",
    "Warning: Need to deal with images that are not multiple of 8\n",
    "'''\n",
    "\n",
    "def DCT(img):\n",
    "    Y = np.zeros_like(img)\n",
    "\n",
    "    nLines, nCols = img.shape\n",
    "    U = nLines//8\n",
    "    V = nCols//8\n",
    "\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            # img_blck = np.float32(imf[u*8: u*8 + 8, v*8: v*8 + 8]) # float conversion\n",
    "            img_blck = img[u*8: u*8 + 8, v*8: v*8 + 8]\n",
    "            Y[u*8: u*8 + 8, v*8: v*8 + 8] = cv.dct(img_blck)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT + Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: quant_DCT\n",
    "Description:\n",
    "    For each block 8x8 from the image transformed\n",
    "    Is divided by the quantization matrix\n",
    "\n",
    "Input: image transformed\n",
    "Output: image tranformed divided by quantization \n",
    "'''\n",
    "\n",
    "def quant_DCT(Y):\n",
    "    Y_quant = np.zeros(Y.shape)\n",
    "    U = Y.shape[0]//8\n",
    "    V = Y.shape[1]//8\n",
    "\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            Y_quant[u*8 : u*8 + 8, v*8 : v*8 + 8] = (Y[u*8 : u*8 + 8, v*8 : v*8 + 8] / quantization_B)\n",
    "    \n",
    "    return Y_quant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequant_DCT(Y_quant):\n",
    "    U = Y_quant.shape[0]//8\n",
    "    V = Y_quant.shape[1]//8\n",
    "    Y_dequant = np.zeros(Y_quant.shape)\n",
    "    \n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            Y_dequant[u*8 : u*8 + 8, v*8 : v*8 + 8] = Y_quant[u*8 : u*8 + 8, v*8 : v*8 + 8] * quantization_B\n",
    "    \n",
    "    return Y_dequant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iDCT(Y):\n",
    "\n",
    "    U = Y.shape[0]//8\n",
    "    V = Y.shape[1]//8\n",
    "    img_rec = np.zeros(Y.shape)\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            img_rec[u*8 : u*8 + 8, v*8 : v*8 + 8] = cv.idct(Y[u*8 : u*8 + 8, v*8 : v*8 + 8])\n",
    "    \n",
    "    return img_rec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution and Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('imgs/naruto.webp', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "# plt.imshow(img, cmap='gray')\n",
    "img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf = np.float32(img) - 128\n",
    "Y = DCT(imf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(Y)\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((Y), cmap='gray')\n",
    "(np.unique(Y).size, np.unique(img).size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_quant = quant_DCT(Y)\n",
    "# Y_quant = np.round(quant_DCT(Y))\n",
    "Y_quant = np.trunc(quant_DCT(Y))\n",
    "# plt.hist(Y_quant)\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nums = np.unique(Y_quant)\n",
    "print(f'Imagem Original: {np.unique(img).size}    |     Imagem Tranformada Quantizada: {np.unique(Y_quant).size}')\n",
    "print(f'Numero de Zeros na Imagem {(Y_quant == 0).sum()},  Numero de Pixels da Imagem {img.size}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de Predição + matriz de erros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, V = Y_quant.shape\n",
    "\n",
    "Error_predic1 = np.zeros(Y_quant.shape)\n",
    "Error_predic2 = np.zeros(Y_quant.shape)\n",
    "for u in range(U):\n",
    "    for v in range(V):\n",
    "        Error_predic1[u][v] = Y_quant[u][v] - predict_function_1(u, v, Y_quant)\n",
    "        Error_predic2[u][v] = Y_quant[u][v] - predict_function_2(u, v, Y_quant)\n",
    "\n",
    "\n",
    "Error_predic1[0][0] = Error_predic2[0][0] = Y_quant[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Y_quant have {np.unique(Y_quant).size} unique values')\n",
    "print(f'Error_predict1 have {np.unique(np.trunc(Error_predic1)).size} unique values')\n",
    "print(f'Error predict2 have {np.unique(np.trunc(Error_predic2)).size} unique values')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Func: weight_grey_tons\n",
    "Description:\n",
    "    Get the number of occurrence of each color\n",
    "Input: quantizated transformed image (Future: Error quantizated transformed image)\n",
    "Output: table with the occurrence of each color\n",
    "    [0     4] -> color 0 -> 4 times\n",
    "    [1     1] -> color 1 -> 1 time\n",
    "    [2     5]\n",
    "    [3     6]\n",
    "'''\n",
    "\n",
    "def weight_grey_tons(img):\n",
    "    # depth = 8\n",
    "    # nLine, nCols = img.shape\n",
    "    # hist = np.zeros((2**8))\n",
    "    \n",
    "    #get unique values and counts of each value\n",
    "    unique, counts = np.unique(img.flatten(), return_counts=True)\n",
    "\n",
    "    #display unique values and counts side by side\n",
    "    occurrence = np.asarray((unique, counts)).T\n",
    "\n",
    "    return occurrence\n",
    "\n",
    "'''\n",
    "Func: huffman_tree\n",
    "Description:\n",
    "    Create the the tree representation for the Huff Algorithm\n",
    "Input: Color occurency \n",
    "    Accept Format\n",
    "    [0     4] -> color 0 -> 4 times\n",
    "    [1     1] -> color 1 -> 1 time\n",
    "    [2     5]\n",
    "    [3     6]\n",
    "\n",
    "Output: Tree\n",
    "\n",
    "To-do\n",
    "    Priority_queue\n",
    "    Tree\n",
    "'''\n",
    "\n",
    "def huffman_tree(ocurrence):\n",
    "\n",
    "    nLine, _ = ocurrence.shape\n",
    "    \n",
    "    class Tree:\n",
    "        def __init__(self, data):\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.data = data\n",
    "\n",
    "    forest = []\n",
    "\n",
    "    # Populate the list\n",
    "    for i in range (nLine):\n",
    "        color, times =  ocurrence[i]\n",
    "        tree = Tree(color)\n",
    "        forest.append((times, color, tree)) # Why a tuple? Is easier to use a tuple than define a __lt__ to compare the objects\n",
    "\n",
    "    # Create a priority list\n",
    "    heapq.heapify(forest)\n",
    "\n",
    "\n",
    "    count = 300\n",
    "    while(len(forest) > 0):\n",
    "        first_small = heapq.heappop(forest)\n",
    "        second_small = heapq.heappop(forest)\n",
    "\n",
    "        tree\n",
    "\n",
    "    return first_small, second_small\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = weight_grey_tons(img)\n",
    "huffman_tree(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconpress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dequantizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dequant = dequant_DCT(Y_quant)\n",
    "np.unique(Y_dequant).max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformada inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rec = iDCT(Y_dequant)\n",
    "img_rec += 128\n",
    "\n",
    "# Corrige os pixies que estouraram\n",
    "filtro = img_rec > 255\n",
    "img_rec[filtro] = 255\n",
    "\n",
    "filtro = img_rec < 0\n",
    "img_rec[filtro] = 0\n",
    "# img_rec *= rate\n",
    "img_rec = np.round(img_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((img_rec), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((img), cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {((img - img_rec)**2).sum()/img.size}')\n",
    "print(f'ME: {np.abs(img - img_rec).max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramas de Y e Y_quant para, posteriormente, criar matriz de erros para huffman\n",
    "# observe o eixo-x, i.e. os erros serão mais próximos\n",
    "plt.hist(Y)\n",
    "plt.show()\n",
    "plt.hist(Y_quant)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.unique(Y).size, np.unique(Y_quant).size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
