{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.fftpack import dct, idct\n",
    "import heapq\n",
    "import bitarray.util as bit\n",
    "import bitarray\n",
    "import skimage.measure "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DCT Function\n",
    "Description:\n",
    "    Calculate the transformed of a image, breaking it in bloks of 8x8\n",
    "    Use two times the dct for 1D, each time for one axis of the image\n",
    "Input: Original image\n",
    "Output: image transformed\n",
    "Warning: Need to deal with images that are not multiple of 8\n",
    "'''\n",
    "\n",
    "def DCT(img):\n",
    "    Y = np.zeros_like(img)\n",
    "\n",
    "    nLines, nCols = img.shape\n",
    "    U = nLines//8\n",
    "    V = nCols//8\n",
    "\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            # img_blck = np.float32(imf[u*8: u*8 + 8, v*8: v*8 + 8]) # float conversion\n",
    "            img_blck = img[u*8: u*8 + 8, v*8: v*8 + 8]\n",
    "            Y[u*8: u*8 + 8, v*8: v*8 + 8] = cv.dct(img_blck)\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT + Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: quant_DCT\n",
    "Description:\n",
    "    For each block 8x8 from the image transformed\n",
    "    Is divided by the quantization matrix\n",
    "\n",
    "Input: image transformed\n",
    "Output: image tranformed divided by quantization \n",
    "'''\n",
    "\n",
    "def quant_DCT(Y, quantization):\n",
    "    Y_quant = np.zeros(Y.shape)\n",
    "    U = Y.shape[0]//8\n",
    "    V = Y.shape[1]//8\n",
    "\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            Y_quant[u*8 : u*8 + 8, v*8 : v*8 + 8] = (Y[u*8 : u*8 + 8, v*8 : v*8 + 8] / quantization)\n",
    "    \n",
    "    return Y_quant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTree:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "    def insert(self, data):\n",
    "        if self.data == data:\n",
    "            return\n",
    "        elif self.data < data:\n",
    "            if self.right is None:\n",
    "                self.right = BinaryTree(data)\n",
    "            else:\n",
    "                self.right.insert(data)\n",
    "        else: # self.data > data\n",
    "            if self.left is None:\n",
    "                self.left = BinaryTree(data)\n",
    "            else:\n",
    "                self.left.insert(data)\n",
    "    def display(self):\n",
    "        lines, *_ = self._display_aux()\n",
    "        for line in lines:\n",
    "            print(line)\n",
    "    def _display_aux(self):\n",
    "        \"\"\"Returns list of strings, width, height, and horizontal coordinate of the root.\"\"\"\n",
    "        # No child.\n",
    "        if self.right is None and self.left is None:\n",
    "            line = '%s' % self.data\n",
    "            width = len(line)\n",
    "            height = 1\n",
    "            middle = width // 2\n",
    "            return [line], width, height, middle\n",
    "        # Only left child.\n",
    "        if self.right is None:\n",
    "            lines, n, p, x = self.left._display_aux()\n",
    "            s = '%s' % self.data\n",
    "            u = len(s)\n",
    "            first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s\n",
    "            second_line = x * ' ' + '/' + (n - x - 1 + u) * ' '\n",
    "            shifted_lines = [line + u * ' ' for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, n + u // 2\n",
    "        # Only right child.\n",
    "        if self.left is None:\n",
    "            lines, n, p, x = self.right._display_aux()\n",
    "            s = '%s' % self.data\n",
    "            u = len(s)\n",
    "            first_line = s + x * '_' + (n - x) * ' '\n",
    "            second_line = (u + x) * ' ' + '\\\\' + (n - x - 1) * ' '\n",
    "            shifted_lines = [u * ' ' + line for line in lines]\n",
    "            return [first_line, second_line] + shifted_lines, n + u, p + 2, u // 2\n",
    "        # Two children.\n",
    "        left, n, p, x = self.left._display_aux()\n",
    "        right, m, q, y = self.right._display_aux()\n",
    "        s = '%s' % self.data\n",
    "        u = len(s)\n",
    "        first_line = (x + 1) * ' ' + (n - x - 1) * '_' + s + y * '_' + (m - y) * ' '\n",
    "        second_line = x * ' ' + '/' + (n - x - 1 + u + y) * ' ' + '\\\\' + (m - y - 1) * ' '\n",
    "        if p < q:\n",
    "            left += [n * ' '] * (q - p)\n",
    "        elif q < p:\n",
    "            right += [m * ' '] * (p - q)\n",
    "        zipped_lines = zip(left, right)\n",
    "        lines = [first_line, second_line] + [a + u * ' ' + b for a, b in zipped_lines]\n",
    "        return lines, n + m + u, max(p, q) + 2, n + u // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Func: weight_grey_tons\n",
    "Description:\n",
    "    Get the number of occurrence of each color\n",
    "Input: quantizated transformed image (Future: Error quantizated transformed image)\n",
    "Output: table with the occurrence of each color\n",
    "    [0     4] -> color 0 -> 4 times\n",
    "    [1     1] -> color 1 -> 1 time\n",
    "    [2     5]\n",
    "    [3     6]\n",
    "'''\n",
    "\n",
    "def weight_grey_tons(img):\n",
    "    # depth = 8\n",
    "    # nLine, nCols = img.shape\n",
    "    # hist = np.zeros((2**8))\n",
    "    \n",
    "    #get unique values and counts of each value\n",
    "    unique, counts = np.unique(img.flatten(), return_counts=True)\n",
    "\n",
    "    #display unique values and counts side by side\n",
    "    occurrence = np.asarray((unique, counts)).T\n",
    "\n",
    "    return occurrence\n",
    "\n",
    "'''\n",
    "Func: huffman_tree\n",
    "Description:\n",
    "    Create the the tree representation for the Huff Algorithm\n",
    "Input: Color occurency \n",
    "    Accept Format\n",
    "    [0     4] -> color 0 -> 4 times\n",
    "    [1     1] -> color 1 -> 1 time\n",
    "    [2     5]\n",
    "    [3     6]\n",
    "\n",
    "Output: Tree\n",
    "\n",
    "To-do\n",
    "    Priority_queue\n",
    "    Tree\n",
    "'''\n",
    "\n",
    "def huffman_tree(ocurrence):\n",
    "\n",
    "    nLine, _ = ocurrence.shape\n",
    "    \n",
    "    class Tree:\n",
    "        def __init__(self, data):\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.data = data\n",
    "\n",
    "    forest = []\n",
    "\n",
    "    # Populate the list\n",
    "    for i in range (nLine):\n",
    "        color, times =  ocurrence[i]\n",
    "        tree = BinaryTree(color)\n",
    "        forest.append((times, color, tree)) # Why a tuple? Is easier to use a tuple than define a __lt__ to compare the objects\n",
    "\n",
    "    # Create a priority list\n",
    "    heapq.heapify(forest)\n",
    "\n",
    "    # Variable to Simulate a Stable Sort\n",
    "    # And to sort first the leaf with data -> (data is a value of the gray scale)\n",
    "    count = 300\n",
    "    while(len(forest) > 1):\n",
    "        f_times, f_color, f_tree = heapq.heappop(forest)\n",
    "        s_times, s_color, s_tree = heapq.heappop(forest)\n",
    "\n",
    "        new_tree = BinaryTree(None)\n",
    "        new_tree.left = f_tree\n",
    "        new_tree.right = s_tree\n",
    "        heapq.heappush(forest, (f_times + s_times, count, new_tree))\n",
    "        count += 1\n",
    "    \n",
    "\n",
    "    _, _, h_tree = heapq.heappop(forest)\n",
    "\n",
    "    string_to_encode = []\n",
    "    \n",
    "    def printPostorder(node, str):\n",
    " \n",
    "        if node:\n",
    "    \n",
    "            # First recur on left child\n",
    "            printPostorder(node.left, str)\n",
    "    \n",
    "            # the recur on right child\n",
    "            printPostorder(node.right, str)\n",
    "    \n",
    "            # now print the data of node\n",
    "            if node.data != None:\n",
    "                str.append(1)\n",
    "                str.append('c')\n",
    "                str.append(np.uint8(node.data))\n",
    "            else:\n",
    "                str.append(0)\n",
    "    \n",
    "\n",
    "    printPostorder(h_tree, string_to_encode)\n",
    "    # Mark the end of the tree\n",
    "    string_to_encode.append(0)\n",
    "    return h_tree, string_to_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_string(arr, unique_values):\n",
    "    num_bits = unique_values * 8 + unique_values * 2\n",
    "\n",
    "    num_blocks = int(np.ceil(num_bits / 8))\n",
    "\n",
    "    header = np.zeros((num_blocks), dtype=np.uint8)\n",
    "    \n",
    "    # Array index\n",
    "    i = 0\n",
    "\n",
    "    # Block Index\n",
    "    k = 0\n",
    "\n",
    "    # Index inside the Block\n",
    "    j = 8\n",
    "\n",
    "    while (i < len(arr)):\n",
    "\n",
    "        if arr[i] == 0 or arr[i] == 1:\n",
    "            header[k] += arr[i] << (j - 1)\n",
    "            j -= 1\n",
    "        \n",
    "        elif arr[i] == 'c':\n",
    "            i += 1\n",
    "            \n",
    "            binary = bin(arr[i])[2:]\n",
    "            to_complete_8_bits = 8 - len(binary)\n",
    "\n",
    "            for count in range(to_complete_8_bits):\n",
    "                if j == 0:\n",
    "                    j = 8\n",
    "                    k += 1\n",
    "                j -= 1\n",
    "            \n",
    "            for count in range(len(binary)):\n",
    "                if j == 0:\n",
    "                    j = 8\n",
    "                    k += 1\n",
    "                \n",
    "                header[k] += int(binary[count]) << j - 1\n",
    "                j -= 1\n",
    "            \n",
    "\n",
    "        i += 1\n",
    "        if j == 0:\n",
    "            j = 8\n",
    "            k += 1\n",
    "\n",
    "    return header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_algorithm(img):\n",
    "    occurrence = weight_grey_tons(img)\n",
    "    h_tree, string_to_encode = huffman_tree(occurrence)\n",
    "    header = encode_string(string_to_encode, np.unique(img).size)\n",
    "\n",
    "    return h_tree, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## img codification\n",
    "def pos_order(path:str, node, dictionary:dict):\n",
    "    lft = node.left\n",
    "    rgt = node.right\n",
    "\n",
    "    if lft == None and rgt == None:\n",
    "        dictionary[node.data] = path\n",
    "    else:\n",
    "        pos_order(path + '0', lft, dictionary)\n",
    "        pos_order(path + '1', rgt, dictionary)\n",
    "\n",
    "def create_dictionary(tree):\n",
    "    dictionary = {}\n",
    "    pos_order('', tree, dictionary)\n",
    "    return dictionary\n",
    "\n",
    "def encode_matrix(tree, matrix):\n",
    "    dictionary = create_dictionary(tree)\n",
    "    M, N = matrix.shape\n",
    "\n",
    "    binaryString = ''\n",
    "    for i in range(M):\n",
    "        for j in range(N):\n",
    "            binaryString += dictionary[matrix[i][j]]\n",
    "\n",
    "    return bitarray.bitarray(binaryString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para compressão\n",
    "# input_image_file: arquivo de entrada contendo a imagem\n",
    "# compressed_file: arquivo de saída contendo a imagem comprimida\n",
    "def compress_image(input_image_file: str, compressed_file: str):\n",
    "# código da função\n",
    "    img = cv.imread(input_image_file, cv.IMREAD_GRAYSCALE)\n",
    "    quantization_jpeg = np.array([\n",
    "        [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "        [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "        [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "        [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "        [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "        [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "        [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "        [72, 92, 95, 98, 112, 100, 103, 99],\n",
    "    ])\n",
    "\n",
    "    quantization_high_quality = np.array([\n",
    "        [8, 6, 5, 8, 12, 20, 26, 31],\n",
    "        [6, 6, 7, 10, 13, 29, 30, 28],\n",
    "        [7, 7, 8, 12, 20, 29, 35, 28],\n",
    "        [7, 9, 11, 15, 26, 44, 40, 31],\n",
    "        [9, 11, 19, 28, 34, 55, 52, 39],\n",
    "        [12, 18, 28, 32, 41, 52, 57, 46],\n",
    "        [25, 32, 39, 44, 52, 61, 60, 51],\n",
    "        [36, 46, 48, 49, 56, 50, 52, 50],\n",
    "    ])\n",
    "\n",
    "    img -= 128\n",
    "    img = np.float32(img)\n",
    "\n",
    "    dct_img = DCT(img)\n",
    "    high_quant_img = np.trunc(quant_DCT(dct_img, quantization_high_quality))\n",
    "    jpeg_quant_img = np.trunc(quant_DCT(dct_img, quantization_jpeg))\n",
    "\n",
    "\n",
    "\n",
    "    # Calc Entropy   \n",
    "    high_entropy = skimage.measure.shannon_entropy(high_quant_img)\n",
    "    jpeg_entropy = skimage.measure.shannon_entropy(jpeg_quant_img)\n",
    "\n",
    "    # Quantization table used\n",
    "    # 0 is Jpeg Quantization table\n",
    "    # 1 is High Quality quantization table\n",
    "    jpeg_is_better = jpeg_entropy > high_entropy\n",
    "    Q =  0 if jpeg_is_better else 1\n",
    "    quant_img = jpeg_quant_img if jpeg_is_better else high_quant_img\n",
    "\n",
    "    # Calc the huff encoding\n",
    "    # Sum 128 to convert all numbers to positive\n",
    "    quant_img += 128\n",
    "\n",
    "    if quant_img.min() < 0 or quant_img.max() > 255:\n",
    "        exit(3)\n",
    "        \n",
    "    tree, huff_codification = huffman_algorithm(quant_img)\n",
    "\n",
    "    # Create the header\n",
    "    header = np.zeros((1 + 4 + 4 + 2 + huff_codification.size), dtype=np.uint8)\n",
    "    header[0] = Q\n",
    "    print('Tamanho Huffman::', huff_codification.size)\n",
    "    N, M = quant_img.shape\n",
    "\n",
    "    # Number of lines\n",
    "    N_bin = bin(N)[2:]\n",
    "    N_bin = '0' * (32 - len(N_bin)) + N_bin\n",
    "    for i in range(1, 1 + 4):\n",
    "        for j in range(8):\n",
    "            header[i] += int(N_bin[8*(i - 1) + j]) << 8 - (j+1)\n",
    "    \n",
    "    # Number of columns\n",
    "    M_bin = bin(M)[2:]\n",
    "    M_bin = '0' * (32 - len(M_bin)) + M_bin\n",
    "    for i in range(5, 1 + 4 + 4):\n",
    "        for j in range(8):\n",
    "            header[i] += int(M_bin[8* (i - 5) + j]) << 8 - (j+1)\n",
    "    \n",
    "    \n",
    "    # Number of bytes in the huffman encoding\n",
    "    size_enconding = huff_codification.size\n",
    "    size_enconding_bin = bin(size_enconding)[2:]\n",
    "    size_enconding_bin = '0' * (16 - len(size_enconding_bin)) + size_enconding_bin\n",
    "\n",
    "    for i in range(9, 1 + 4 + 4 + 2):\n",
    "        for j in range(8):\n",
    "            header[i] += int(size_enconding_bin[8* (i - 9) + j]) << 8 - (j+1)\n",
    "\n",
    "    \n",
    "    # Copy huffman Encoding\n",
    "    for i in range(11, 11 + huff_codification.size):\n",
    "        header[i] = huff_codification[i - 11]\n",
    "\n",
    "    # Crete the img Codification (Alves)\n",
    "    encodedImg = encode_matrix(tree, quant_img)\n",
    "\n",
    "    #Create compressed binary file\n",
    "    outFile = open(compressed_file, 'wb')\n",
    "\n",
    "    for byte in header:\n",
    "        outFile.write(byte)\n",
    "    outFile.write(encodedImg)\n",
    "\n",
    "    outFile.close()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompress"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncode_header(header):\n",
    "    stack = []\n",
    "\n",
    "    # Block Index\n",
    "    k = 0\n",
    "\n",
    "    # Index inside the Block\n",
    "    j = 0\n",
    "\n",
    "    color = 0\n",
    "\n",
    "\n",
    "    # Complete with zeros binaries less than 8 bits\n",
    "    def binary_8bits(num):\n",
    "        binary = bin(num)[2:]\n",
    "        binary = '0' * (8 - len(binary)) + binary\n",
    "        return binary\n",
    "    \n",
    "    def increase_j(j):\n",
    "        j_equal_eight = j == 7\n",
    "        j = 0 if j_equal_eight else j + 1\n",
    "        return j, j_equal_eight\n",
    "    \n",
    "    def change_block(j, k, bits):\n",
    "        j, change_block = increase_j(j)\n",
    "        if change_block:\n",
    "            k += 1\n",
    "            bits = binary_8bits(header[k])\n",
    "        \n",
    "        return j, k, bits\n",
    "\n",
    "    binary = binary_8bits(header[0])\n",
    "    \n",
    "    while True:\n",
    "        if int(binary[j]) == 1:\n",
    "            print('ok')\n",
    "            j, k, binary = change_block(j, k, binary)\n",
    "                        \n",
    "            for i in range(8):\n",
    "                color = (color << 1) + int(binary[j])\n",
    "                j, k, binary = change_block(j, k, binary)    \n",
    "\n",
    "            stack.append(BinaryTree(color))\n",
    "            color = 0\n",
    "            print(j, k, binary)\n",
    "        \n",
    "        elif int(binary[j]) == 0:\n",
    "            if (len(stack) > 1):\n",
    "                last_tree = stack.pop()\n",
    "                before_last_tree = stack.pop()\n",
    "\n",
    "                new_tree = BinaryTree(None)\n",
    "                new_tree.left = before_last_tree\n",
    "                new_tree.right = last_tree\n",
    "\n",
    "                stack.append(new_tree)\n",
    "                j, k, binary = change_block(j, k, binary)\n",
    "\n",
    "            else:\n",
    "                return stack[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequant_DCT(Y_quant, quantization):\n",
    "    U = Y_quant.shape[0]//8\n",
    "    V = Y_quant.shape[1]//8\n",
    "    Y_dequant = np.zeros(Y_quant.shape)\n",
    "    \n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            Y_dequant[u*8 : u*8 + 8, v*8 : v*8 + 8] = Y_quant[u*8 : u*8 + 8, v*8 : v*8 + 8] * quantization\n",
    "    \n",
    "    return Y_dequant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iDCT(Y):\n",
    "\n",
    "    U = Y.shape[0]//8\n",
    "    V = Y.shape[1]//8\n",
    "    img_rec = np.zeros(Y.shape)\n",
    "    for u in range(U):\n",
    "        for v in range(V):\n",
    "            img_rec[u*8 : u*8 + 8, v*8 : v*8 + 8] = cv.idct(Y[u*8 : u*8 + 8, v*8 : v*8 + 8])\n",
    "    \n",
    "    return img_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatBytes(list):\n",
    "    binStr = ''\n",
    "    for i in range(len(list)):\n",
    "        byte = bin(list[i])[2:]\n",
    "        byte = '0' * (8 - len(byte)) + byte \n",
    "        binStr += byte\n",
    "\n",
    "    bitArr = bitarray.bitarray(binStr)\n",
    "    dic = {\n",
    "        \"bitarray\": bitArr,\n",
    "        \"int\": bit.ba2int(bitArr)\n",
    "    }\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho Huffman:: 457\n",
      "A matriz de quantização escolhida eh: 1\n",
      "Seu tamanho eh (M x N): (1080, 1920)\n",
      "Tamanho do Hoofman eh: 457 bytes\n",
      "Hoofman: bitarray('10010101111000000111000101110110001110100001100101111001101100001101100011101100110011010011011010111100111000011100110110010011001000000110000100110010001110100100111111110100100111010100101010111011110100111000011001010100010101010000011000101010100111001010111000101100000100111101001010001101010000011001111000101001011101011010000000010111110011011010010101111111010110100101110010010100111101010101101010001000001010010001010010010101001100100111111001010110011010101110110100010101100000101011011110100101001110000011110001100100100100111001100111010111000001010111110000100111011101001101111011001111101100011111110110001001100100110010100111010010100011010100100000101001111111011010011101101111101110100001111000001111001000111101011111110001001111100111111101010111111001100000000000100000001100000011010000111010000111100100010000100010101010001011110000010010001001000000010111000100010111011010010101110010110101001011111001101100010011100110011101101010000101010001010001010001111111000110111100101111100110001111010001111011010111110110111111100000010000010010000010101000001101000010000011111011011111100101111110111111111010011111111011111111101000000101000001110000100001000100001011010000111010001000000100010110100011011010001110010001111000010010000110010001001001001001001001100010010011110011110101010000011010001000000001100101100110110001101011110101100101000010010101000110001111101000000010011010101001110001010100100000110011110110100001010011101011110101011110111001111110101000000100010000110110111100001011101010010110101110111001000101010101000100101100101011001110110011011011011010011111000001001101110101000101110011100101010011100100001001100100100110011101000101111010110010000110011111100101001110111100111001010001110010111000100100100011000100011001000101101101000001011100111000111101001000100101011100011011110101101011100011001101011011001010001110001001001011010110000010110111100010111011111000111010110001010011001101010100011010100000101010101010110100100000110001101111000000100101110010101110111010101111100011100111001110111011111010001000110001101100000100100110100110001100110101001001110001001111000101000000101001100000111010000111010010011110100111111001000100001001100001100010110010010110011100001100100110101100111101010111101011010001011011100001100011001101011001101010010110010111000001011111101100000100001011111111011010011011011000101010011011010000001001100010110101000101010110110110000001101101011110000100111001001111011000000010111110001100010000110000110010111010010111100101010100011001011011011010000100110100100011101100011111010101000000000101111000101111011100101111100110000001011101100000101111101110000101101110101101110100010110101010100101011011100001101110011101111110001110001001000101000100110100101001011011100100011100111100011101001111101111001000101101000011111000100110001001001011001010000100101001100101010001001011001001100000100110111100111110000000101101111000001100101001011100010100111111101000011010100100110101001000111000101111010100011110001011111010000011111011111111100001000010101000010110010110011010110111001011100001011100110000110011001011111111101101010100010110110110110010001101001111011011001011000101011110100110111011011101010110010001100001011010100001011110111100010011010111100001011010001100110001100110110101011000101011101011010001110101101111011111000000110000111011011101010110010101101101111001110011010001110011101011010010000001001010001010000100010011001110100110101010101001110011010011101000111101110001111000011111001110000010111000011110111111111000001111110111000110100010110000101011010110000011000001100000011000000000000000')\n"
     ]
    }
   ],
   "source": [
    "# função para descompressão\n",
    "# compressed_file: arquivo contendo a imagem comprimida\n",
    "# output_image_file: arquivo contendo a imagem reconstruída\n",
    "def decompress_image(compressed_file: str, output_image_file: str):\n",
    "    output = open(output_image_file, 'wb')\n",
    "\n",
    "    with open(compressed_file, 'rb') as f:\n",
    "        quantization = f.read(1)[0]\n",
    "        M = concatBytes(f.read(4))\n",
    "        N = concatBytes(f.read(4))\n",
    "        hoofmanLen = concatBytes(f.read(2))['int']\n",
    "        print(f'A matriz de quantização escolhida eh: {quantization}')\n",
    "        print(f'Seu tamanho eh (M x N): ({(M[\"int\"])}, {N[\"int\"]})')\n",
    "        print(f'Tamanho do Hoofman eh: {hoofmanLen} bytes')\n",
    "\n",
    "        hoofman = concatBytes(f.read(hoofmanLen))\n",
    "        print(f'Hoofman: {hoofman[\"bitarray\"]}')\n",
    "\n",
    "\n",
    "        # while True:\n",
    "        #     byte_s = f.read(1)\n",
    "        #     print(byte_s)\n",
    "        #     if not byte_s:\n",
    "\n",
    "        #         break\n",
    "        #     byte = byte_s[0]\n",
    "\n",
    "compress_image('imgs/horizon.png', 'compressed.bin')\n",
    "decompress_image('compressed.bin', 'out.jpg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution and Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d91817370>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv.imread('imgs/listrada.png', cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m compression(img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compression' is not defined"
     ]
    }
   ],
   "source": [
    "compression(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imf = np.float32(img) - 128\n",
    "Y = DCT(imf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((Y), cmap='gray')\n",
    "(np.unique(Y).size, np.unique(img).size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_quant = quant_DCT(Y)\n",
    "# Y_quant = np.round(quant_DCT(Y))\n",
    "Y_quant = np.trunc(quant_DCT(Y))\n",
    "# Y_quant += 128\n",
    "# plt.hist(Y_quant)\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nums = np.unique(Y_quant)\n",
    "print(f'Imagem Original: {np.unique(img).size}    |     Imagem Tranformada Quantizada: {np.unique(Y_quant).size}')\n",
    "print(f'Numero de Zeros na Imagem {(Y_quant == 0).sum()},  Numero de Pixels da Imagem {img.size}')\n",
    "print(f'rate: {(Y_quant == 0).sum() / img.size}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique values and counts of each value\n",
    "unique, counts = np.unique(img, return_counts=True)\n",
    "\n",
    "#display unique values and counts side by side\n",
    "print(np.asarray((np.uint8(unique), counts)).T)\n",
    "print(unique.min(), unique.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = weight_grey_tons(img)\n",
    "tree, to_encode = huffman_tree(output)\n",
    "tree.display()\n",
    "print()\n",
    "print(to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "header = encode_string(to_encode, np.unique(img).size)\n",
    "header\n",
    "for i in range(len(header)):\n",
    "    print(bin(header[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(img, density=True)\n",
    "x = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconpress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(header)):\n",
    "    print(bin(header[i]))\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = bin(header[1])[2:]\n",
    "binary = '0' * (8 - len(binary)) + binary\n",
    "binary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huffman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huffman_tree_uncoded = uncode_header(header)\n",
    "huffman_tree_uncoded.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dequantizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dequant = dequant_DCT(Y_quant)\n",
    "np.unique(Y_dequant).max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformada inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rec = iDCT(Y_dequant)\n",
    "img_rec += 128\n",
    "\n",
    "# Corrige os pixies que estouraram\n",
    "filtro = img_rec > 255\n",
    "img_rec[filtro] = 255\n",
    "\n",
    "filtro = img_rec < 0\n",
    "img_rec[filtro] = 0\n",
    "# img_rec *= rate\n",
    "img_rec = np.round(img_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((img_rec), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((img), cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análises\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {((img - img_rec)**2).sum()/img.size}')\n",
    "print(f'ME: {np.abs(img - img_rec).max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramas de Y e Y_quant para, posteriormente, criar matriz de erros para huffman\n",
    "# observe o eixo-x, i.e. os erros serão mais próximos\n",
    "plt.hist(Y)\n",
    "plt.show()\n",
    "plt.hist(Y_quant)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.unique(Y).size, np.unique(Y_quant).size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
